{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874061c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5ac70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51bb3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_img_path_list = []\n",
    "# train_df_img_label = []\n",
    "# train_df = pd.DataFrame(columns=[\"img_path\",\"label\"])\n",
    "# for idx, i in enumerate(os.listdir(\"Image Classification Data/data/train\")):\n",
    "#     for j in enumerate(os.listdir(f\"Image Classification Data/data/train/{i}\")):\n",
    "#         train_df_img_path_list.append(f\"Image Classification Data/data/train/{i}/{j[1]}\")\n",
    "#         train_df_img_label.append(idx)\n",
    "# train_df[\"img_path\"] = train_df_img_path_list\n",
    "# train_df[\"label\"] = train_df_img_label\n",
    "# train_df.to_csv (r'train_csv.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96185726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_img_path_list = []\n",
    "# test_df_img_label = []\n",
    "# test_df = pd.DataFrame(columns=[\"img_path\",\"label\"])\n",
    "# for idx, i in enumerate(os.listdir(\"Image Classification Data/data/test\")):\n",
    "#     for j in enumerate(os.listdir(f\"Image Classification Data/data/test/{i}\")):\n",
    "#         test_df_img_path_list.append(f\"Image Classification Data/data/test/{i}/{j[1]}\")\n",
    "#         test_df_img_label.append(idx)\n",
    "# test_df[\"img_path\"] = test_df_img_path_list\n",
    "# test_df[\"label\"] = test_df_img_label\n",
    "# test_df.to_csv (r'test_csv.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ddae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3d17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded05b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image Classification Data/data/train/colon/400...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image Classification Data/data/train/colon/400...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Classification Data/data/train/colon/400...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image Classification Data/data/train/colon/400...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image Classification Data/data/train/colon/400...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  label\n",
       "0  Image Classification Data/data/train/colon/400...      0\n",
       "1  Image Classification Data/data/train/colon/400...      0\n",
       "2  Image Classification Data/data/train/colon/400...      0\n",
       "3  Image Classification Data/data/train/colon/400...      0\n",
       "4  Image Classification Data/data/train/colon/400...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f1a4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image Classification Data/data/test/colon/4004...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image Classification Data/data/test/colon/4004...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Classification Data/data/test/colon/4004...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image Classification Data/data/test/colon/4004...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image Classification Data/data/test/colon/4004...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  label\n",
       "0  Image Classification Data/data/test/colon/4004...      0\n",
       "1  Image Classification Data/data/test/colon/4004...      0\n",
       "2  Image Classification Data/data/test/colon/4004...      0\n",
       "3  Image Classification Data/data/test/colon/4004...      0\n",
       "4  Image Classification Data/data/test/colon/4004...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95cd1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataloader(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.dataframe[\"img_path\"][index]).convert(\"RGB\")\n",
    "        y_label = self.dataframe[\"label\"][index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e928df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((2000,2000)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449499e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataloader(dataframe = train_df, transform = transform)\n",
    "test_dataset = CustomDataloader(dataframe = test_df, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a312a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle = True, batch_size = 16, pin_memory = True, num_workers = 1)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle = True, batch_size = 16, pin_memory = True, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c40d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, output_dim=12):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn_model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(in_channels = 4,out_channels = 8,kernel_size = 3,padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(in_channels = 8,out_channels = 16,kernel_size = 3,padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024,output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cnn_model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e3a40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_check(loader, model):\n",
    "    num_correct = 0  # keep track of correctly classified Images\n",
    "    num_samples = 0  # keep track of batches checked\n",
    "    model.eval()  # set model in evaluation mode for test accuracy calculation\n",
    "\n",
    "    with torch.no_grad():  # no gradient calculations required during testing\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)  # shift images to GPU\n",
    "            labels = labels.to(device)  # shift labels to GPU\n",
    "            scores = model(imgs)  # predictions vector containing probability of each digit\n",
    "            predictions = torch.tensor([torch.argmax(i).item() for i in scores]).to(device)  # extract digit index with the highest probability\n",
    "            num_correct+= (predictions == labels).sum()  # calculating correctly classified images from the batch\n",
    "            num_samples+= predictions.size(0)  # adding the batch size to total samples counter\n",
    "    acc = float(num_correct)/float(num_samples)*100  # calculating accuracy\n",
    "    print(f\"Got {num_correct} / {num_samples} with test accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "    model.train()  # put the model back in train for further epochs\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f35f15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size):\n",
    "    model_cnn.train()  # setting model to train mode\n",
    "    epoch_lost_list = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for epoch in range(num_epochs):  # itereate through entire dataset in one epoch\n",
    "        epoch_loss = 0\n",
    "        num_correct = 0  # counter to keep track of the total correctly classified images from entire dataset per epoch\n",
    "        num_samples = 0  # counter to keep track of the datapoints iterated in the entire dataset per epoch\n",
    "        print(\"epoch:\", epoch + 1)  # prints epoch number\n",
    "        for imgs, labels in train_dataloader:  # trainloader returns a tuple -> (batch of images, corresponding vector of labels)\n",
    "            # Feedforward Section\n",
    "            imgs = imgs.to(device)  # shift images to GPU for faster training\n",
    "            labels = labels.to(device)  # shift labels to GPU for faster training\n",
    "            outputs = model_cnn(imgs)  # output of feedforward neural network before softmax layer\n",
    "            # Backpropagation Section\n",
    "            loss = criterion(outputs, labels)  # calculate the softmax output and loss per batch of the images\n",
    "            optimizer.zero_grad()  # set the optimizer matrix to zero before calculating the gradients for every batch\n",
    "            loss.backward()  # calculate the gradients through differentiation (dL/dW)\n",
    "            epoch_loss+= loss.item()\n",
    "            optimizer.step()  # updation of weights (w = w - dL/dW)\n",
    "            # Prediction Section\n",
    "            predictions = torch.tensor([torch.argmax(i).item() for i in outputs]).to(device)  # using trained weights to predict the output.\n",
    "            num_correct += (predictions == labels).sum()  # if predictions vector matches labels vector, we increment num_correct by the number of correct predictions\n",
    "            num_samples += predictions.size(0)  # increment the number of samples by batchsize\n",
    "        epoch_lost_list.append(epoch_loss / (len(train_dataset) // batch_size))\n",
    "        train_accuracies.append(float(num_correct) / float(num_samples) * 100)\n",
    "        print(f\"Got {num_correct} / {num_samples} with train accuracy {float(num_correct) / float(num_samples) * 100:.2f}\\n\") # print training accuracy per epoch\n",
    "        print(\"Train Loss Epoch: \",epoch_loss / (len(train_dataset) // batch_size))\n",
    "        # Calculate test accuracy every epoch\n",
    "        test_acc = test_accuracy_check(test_dataloader, model_cnn)\n",
    "        test_accuracies.append(test_acc)\n",
    "        if (epoch+1)%10:\n",
    "            torch.save(model_cnn,f\"trained_classification_model_{epoch + 1}.pt\")\n",
    "    \n",
    "    file_name_1 = \"train_loss.pkl\"\n",
    "    file_name_2 = \"train_acc.pkl\"\n",
    "    file_name_3 = \"test_acc.pkl\"\n",
    "    open_file_1 = open(file_name_1, \"wb\")\n",
    "    open_file_2 = open(file_name_2, \"wb\")\n",
    "    open_file_3 = open(file_name_3, \"wb\")\n",
    "    pickle.dump(epoch_lost_list, open_file_1)\n",
    "    pickle.dump(train_accuracies, open_file_2)\n",
    "    pickle.dump(test_accuracies, open_file_3)\n",
    "    open_file_1.close()\n",
    "    open_file_2.close()\n",
    "    open_file_3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ebf7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75bc7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = CNN().to(device)  # model will run on GPU\n",
    "criterion = nn.CrossEntropyLoss()  # function callout for softmax output and loss calculation\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=learning_rate)  # Optimizer set to Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac53cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
