{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8741e914",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874061c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import random\n",
    "import logging\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# WandB – Import the wandb library\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541cb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f30dd",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c902ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # setting model to train mode\n",
    "    for imgs, labels in train_loader:  # trainloader returns a tuple -> (batch of images, corresponding vector of labels)\n",
    "        # Feedforward Section\n",
    "        imgs = imgs.to(device)  # shift images to GPU for faster training\n",
    "        labels = labels.to(device)  # shift labels to GPU for faster training\n",
    "        outputs = model(imgs)  # output of feedforward neural network before softmax layer\n",
    "        # Backpropagation Section\n",
    "        loss = F.cross_entropy(outputs, labels)  # calculate the softmax output and loss per batch of the images\n",
    "        optimizer.zero_grad()  # set the gradients matrix to zero before calculating the gradients for every batch\n",
    "        loss.backward()  # calculate the gradients through differentiation (dL/dW)\n",
    "        optimizer.step()  # updation of weights (w = w - dL/dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec18685",
   "metadata": {},
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1669730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, classes):\n",
    "    num_correct = 0  # keep track of correctly classified Images\n",
    "    test_loss = 0  # keep track of test loss\n",
    "    model.eval()  # set model in evaluation mode for test accuracy calculation\n",
    "    \n",
    "    example_images = []\n",
    "    with torch.no_grad():  # no gradient calculations required during testing\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)  # shift images to GPU\n",
    "            labels = labels.to(device)  # shift labels to GPU\n",
    "            scores = model(imgs)  # predictions vector containing probability of each digit\n",
    "            test_loss+=F.cross_entropy(scores, labels, reduction = 'sum').item()\n",
    "            pred = scores.max(1, keepdim=True)[1]  # extract digit index with the highest probability\n",
    "            num_correct+= pred.eq(labels.view_as(pred)).sum().item()  # calculating correctly classified images from the batch\n",
    "            # WandB – Log images in your test dataset automatically, along with predicted and true labels by passing pytorch tensors with image data into wandb.Image\n",
    "            example_images.append(wandb.Image(\n",
    "                imgs[0], caption=\"Pred: {} Truth: {}\".format(classes[pred[0].item()], classes[labels[0]])))\n",
    "    # WandB – wandb.log(a_dict) logs the keys and values of the dictionary passed in and associates the values with a step.\n",
    "    # You can log anything by passing it to wandb.log, including histograms, custom matplotlib objects, images, video, text, tables, html, pointclouds and other 3D objects.\n",
    "    # Here we use it to log test accuracy, loss and some test images (along with their true and predicted labels).\n",
    "    wandb.log({\n",
    "        \"Examples\": example_images,\n",
    "        \"Test Accuracy\": 100. * num_correct / len(test_loader.dataset),\n",
    "        \"Test Loss\": test_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7cc920",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4cdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define the tranformations to apply to our images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200,200)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "#load datasets\n",
    "train_dataset = ImageFolder(\"Image Classification Data/data/train\",transform)\n",
    "test_dataset = ImageFolder(\"Image Classification Data/data/test\",transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9415552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['colon', 'endometrium_1', 'endometrium_2', 'kidney', 'liver', 'lung', 'lymph_node', 'pancreas', 'skin_1', 'skin_2', 'small_intestine', 'spleen']\n",
      "['colon', 'endometrium_1', 'endometrium_2', 'kidney', 'liver', 'lung', 'lymph_node', 'pancreas', 'skin_1', 'skin_2', 'small_intestine', 'spleen']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.classes)\n",
    "print(test_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28749063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: C:\\Users\\ajinkya2\\AppData\\Local\\Temp/ipykernel_15964/3208814591.py 2 <module>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 954, in init\n",
      "    run = wi.init()\n",
      "  File \"C:\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 614, in init\n",
      "    backend.cleanup()\n",
      "  File \"C:\\Python39\\lib\\site-packages\\wandb\\sdk\\backend\\backend.py\", line 248, in cleanup\n",
      "    self.interface.join()\n",
      "  File \"C:\\Python39\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 467, in join\n",
      "    super().join()\n",
      "  File \"C:\\Python39\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 630, in join\n",
      "    _ = self._communicate_shutdown()\n",
      "  File \"C:\\Python39\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 464, in _communicate_shutdown\n",
      "    _ = self._communicate(record)\n",
      "  File \"C:\\Python39\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 222, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"C:\\Python39\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 227, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    }
   ],
   "source": [
    "# WandB – Initialize a new run\n",
    "wandb.init(entity=\"wandb\", project=\"pytorch-resnet18-classification\")\n",
    "wandb.watch_called = False # Re-run the model without restarting the runtime, unnecessary after our next release\n",
    "\n",
    "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
    "config = wandb.config          # Initialize config\n",
    "config.batch_size = 64          # input batch size for training (default: 64)\n",
    "config.test_batch_size = 1000    # input batch size for testing (default: 1000)\n",
    "config.epochs = 10             # number of epochs to train (default: 10)\n",
    "config.lr = 0.001               # learning rate (default: 0.01)\n",
    "# config.momentum = 0.1          # SGD momentum (default: 0.5) \n",
    "config.no_cuda = False         # disables CUDA training\n",
    "config.seed = 42               # random seed (default: 42)\n",
    "config.log_interval = 10     # how many batches to wait before logging training status\n",
    "\n",
    "def main():\n",
    "    use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    \n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    # random.seed(config.seed)       # python random seed\n",
    "    torch.manual_seed(config.seed) # pytorch random seed\n",
    "    # numpy.random.seed(config.seed) # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    # Now we load our training and test datalaoders\n",
    "    train_loader = DataLoader(train_dataset,batch_size=config.batch_size,shuffle=True, **kwargs)\n",
    "    test_loader = DataLoader(test_dataset,batch_size=config.test_batch_size,shuffle=False, **kwargs)\n",
    "\n",
    "    classes = tuple(label for label in os.listdir(\"Image Classification Data/data/train\"))\n",
    "\n",
    "    ## loading pretrained resnet18 model\n",
    "    model = resnet18(pretrained = True).to(device)\n",
    "    \n",
    "    ## setting grad requirement for weights to false to avoid backpropagation through those layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    ## modifying last layer to change the num of output_features to num of classes in the cats and dogs species dataset \n",
    "    ## grabbing number of neurons in the second last layer\n",
    "    hidden_units_second_last = model.fc.in_features\n",
    "    model.fc = nn.Linear(hidden_units_second_last, len(class_labels)).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "    \n",
    "    # WandB – wandb.watch() automatically fetches all layer dimensions, gradients, model parameters and logs them automatically to your dashboard.\n",
    "    # Using log=\"all\" log histograms of parameter values in addition to gradients\n",
    "    wandb.watch(model, log=\"all\")\n",
    "\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        train(config, model, device, train_loader, optimizer, epoch)\n",
    "        test(config, model, device, test_loader, classes)\n",
    "        \n",
    "    # WandB – Save the model checkpoint. This automatically saves a file to the cloud and associates it with the current run.\n",
    "    torch.save(model.state_dict(), \"model_resnet18_cf.h5\")\n",
    "    wandb.save('model_resnet18_cf.h5')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1882a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
